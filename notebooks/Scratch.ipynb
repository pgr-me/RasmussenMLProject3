{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'KNNClassifier' from 'p3.algorithms' (C:\\Users\\pgr-m\\AppData\\Roaming\\JetBrains\\DataSpell2021.3\\projects\\RasmussenMLProject3\\p3\\algorithms\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_17376/1642473127.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;31m# Local imports\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mp3\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnodes\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mNode\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mp3\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrees\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mTree\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mTreeError\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mp3\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocessing\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mPreprocessor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mget_standardization_cols\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mget_standardization_params\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstandardize\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\JetBrains\\DataSpell2021.3\\projects\\RasmussenMLProject3\\p3\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mp3\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mrun\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Roaming\\JetBrains\\DataSpell2021.3\\projects\\RasmussenMLProject3\\p3\\run.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;31m# Local imports\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mp3\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocessing\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mPreprocessor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mget_standardization_cols\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mget_standardization_params\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstandardize\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mp3\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0malgorithms\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mKNNClassifier\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mKNNRegressor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mp3\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocessing\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmake_splits\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'KNNClassifier' from 'p3.algorithms' (C:\\Users\\pgr-m\\AppData\\Roaming\\JetBrains\\DataSpell2021.3\\projects\\RasmussenMLProject3\\p3\\algorithms\\__init__.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "# Standard library imports\n",
    "import collections as c\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "\n",
    "notebooks_dir = Path(\".\").absolute()\n",
    "repo_dir = notebooks_dir.parent\n",
    "p3_dir = repo_dir / \"p3\"\n",
    "sys.path.append(str(p3_dir))\n",
    "sys.path.append(str(repo_dir))\n",
    "\n",
    "# Third party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Local imports\n",
    "from p3.nodes import Node\n",
    "from p3.trees import Tree, TreeError\n",
    "from p3.preprocessing import Preprocessor, get_standardization_cols, get_standardization_params, standardize\n",
    "from p3.algorithms.classification_entropy import *\n",
    "#from p3.nodes import DecisionNode\n",
    "\n",
    "src_dir = repo_dir / \"data\"\n",
    "# Load data catalog and tuning params\n",
    "with open(src_dir / \"data_catalog.json\", \"r\") as file:\n",
    "    data_catalog = json.load(file)\n",
    "with open(src_dir / \"tuning_params.json\", \"r\") as file:\n",
    "    tuning_params = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Third party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Local imports\n",
    "from p3.nodes import Node\n",
    "\n",
    "\n",
    "class DecisionNode(Node):\n",
    "    \"\"\"\n",
    "    Base node for singly-linked list.\n",
    "    \"\"\"\n",
    "    def __init__(self, mask: pd.Series, name: str, label: str, features: list, data_classes: c.OrderedDict, children=None,\n",
    "                 quantiles=None):\n",
    "        \"\"\"\n",
    "        Set name and optionally set data attributes.\n",
    "        :param mask: Mask used to subset original data to get node data\n",
    "        :param name: Node name\n",
    "        :param label: Label name\n",
    "        :param features: List of features\n",
    "        :param data_classes: Data classes for each feature\n",
    "        :param children: Node children\n",
    "        :param quantiles: Quantiles to split if node is numeric\n",
    "        \"\"\"\n",
    "        # function arguments\n",
    "        super().__init__(name, children)\n",
    "        self.mask = mask\n",
    "        self.name = name\n",
    "        self.label = label\n",
    "        self.features = [x for x in features if x != label]\n",
    "        self.data_classes = data_classes\n",
    "        self.quantiles = quantiles\n",
    "        if quantiles is None:\n",
    "            self.quantiles = [0.25, 0.5, 0.75, 1]\n",
    "        self.entropy = None\n",
    "        self.majority_label = None\n",
    "\n",
    "    def find_best_numeric_split(self, node_data: pd.DataFrame, feature: str, quantiles=None) -> tuple:\n",
    "        \"\"\"\n",
    "        Find best numeric split.\n",
    "        :param node_data:\n",
    "        :param feature: Numeric feature to split\n",
    "        :param quantiles: Quantiles to generate candidate splits for\n",
    "        :return: Tuple of best entropy, mask, and split value for entropy minimizing numeric split\n",
    "        Used as a helper function for split_entropy method, which is based on Equation 9.8 of Alpaydin.\n",
    "        \"\"\"\n",
    "        if quantiles is None:\n",
    "            quantiles = self.quantiles\n",
    "        candidate_split_vals: pd.DataFrame = node_data[feature].quantile(quantiles).drop_duplicates()\n",
    "        best_split_val = None\n",
    "        best_mask = None\n",
    "        best_ent = float(\"inf\")\n",
    "        for candidate_split_val in candidate_split_vals:\n",
    "            candidate_mask: pd.Series = node_data[feature] <= candidate_split_val\n",
    "            candidate_entropy = self.split_entropy_(node_data, candidate_mask)\n",
    "            if candidate_entropy < best_ent:\n",
    "                best_ent = candidate_entropy\n",
    "                best_split_val = candidate_split_val\n",
    "                best_mask = candidate_mask\n",
    "        return best_ent, best_mask, best_split_val\n",
    "\n",
    "    def node_entropy(self, data: pd.DataFrame) -> float:\n",
    "        \"\"\"\n",
    "        Compute the entropy of a class.\n",
    "        :param data: Data of node or one of its branches or candidate branches\n",
    "        :return: Entropy of a node\n",
    "        Based on Equation 9.3 of Alpaydin's Intro to Machine Learning, 4th Ed.\n",
    "        \"\"\"\n",
    "        class_counts = data[self.label].value_counts()\n",
    "        instances = class_counts.sum()\n",
    "        class_fracs = (class_counts / instances)\n",
    "        return -1 * (class_fracs * np.log2(class_fracs)).fillna(0).sum()\n",
    "\n",
    "    def split_attribute(self, data: pd.DataFrame)->dict:\n",
    "        \"\"\"\n",
    "        Find best attribute to split.\n",
    "        :param data: Root dataset\n",
    "        :return: Dictionary of entropy, feature, mask, and split value for child splits\n",
    "        Based on algorithm provided in Figure 9.3 of Alpaydin.\n",
    "        \"\"\"\n",
    "        node_data = data.copy()[self.mask]\n",
    "        best = dict(entropy=float(\"inf\"), feature=None, mask=None, split_value=None)\n",
    "        for feature, data_class in self.data_classes.items():\n",
    "            entropy, mask, split_value = self.split_entropy(node_data, feature, data_class)\n",
    "            if entropy < best[\"entropy\"]:\n",
    "                best = dict(entropy=entropy, feature=feature, mask=mask, split_value=split_value)\n",
    "        return best\n",
    "\n",
    "    def split_entropy(self, data: pd.DataFrame, feature: str, data_class: str) -> tuple:\n",
    "        \"\"\"\n",
    "        Compute split entropy / total impurity.\n",
    "        :param data: Node data\n",
    "        :param feature: Feature to split entropy for\n",
    "        :param data_class: Data class - ordinal, numeric, categorical - of feature\n",
    "        :return: Split entropy / total impurity\n",
    "        Per Equation 9.8 of Alpaydin.\n",
    "        \"\"\"\n",
    "        split_val = None\n",
    "        if data_class == \"categorical\":\n",
    "            split_mask = data[feature].isin([False, 0])\n",
    "            split_ent = self.split_entropy_(data, split_mask)\n",
    "        else:\n",
    "            split_ent, split_mask, split_val = self.find_best_numeric_split(data, feature)\n",
    "        return split_ent, split_mask, split_val\n",
    "\n",
    "    def split_entropy_(self, data: pd.DataFrame, mask: pd.Series) -> float:\n",
    "        \"\"\"\n",
    "        Split entropy for two-branch node.\n",
    "        :param data: Data to split entropy for\n",
    "        :param mask: Mask used to split entropy into left and right branches\n",
    "        Helper function for split_entropy, which is based on Equation 9.8 of Alpaydin.\n",
    "        Left branch is the mask and right branch is that mask's complement.\n",
    "        \"\"\"\n",
    "        left_branch = data.copy()[mask]\n",
    "        right_branch = data.copy()[~mask]\n",
    "        left_branch_entropy = self.node_entropy(left_branch)\n",
    "        right_branch_entropy = self.node_entropy(right_branch)\n",
    "        left_branch_frac = len(left_branch) / len(data)\n",
    "        right_branch_frac = len(right_branch) / len(data)\n",
    "        return left_branch_frac * left_branch_entropy + right_branch_frac * right_branch_entropy\n",
    "\n",
    "    def set_majority_label(self, data: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Set the majority label of a leaf node.\n",
    "\n",
    "        \"\"\"\n",
    "        self.majority_label = data[self.label].mode().iloc[0]\n",
    "        return self.majority_label\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(\n",
    "    [\n",
    "        [\"Sunny\", \"Hot\", \"High\", False, \"N\"],\n",
    "        [\"Sunny\", \"Hot\", \"High\", True, \"N\"],\n",
    "        [\"Overcast\", \"Hot\", \"High\", False, \"P\"],\n",
    "        [\"Rainy\", \"Mild\", \"High\", False, \"P\"],\n",
    "        [\"Rainy\", \"Cool\", \"Normal\", False, \"P\"],\n",
    "        [\"Rainy\", \"Cool\", \"Normal\", True, \"N\"],\n",
    "        [\"Overcast\", \"Cool\", \"Normal\", True, \"P\"],\n",
    "        [\"Sunny\", \"Mild\", \"High\", False, \"N\"],\n",
    "        [\"Sunny\", \"Cool\", \"Normal\", False, \"P\"],\n",
    "        [\"Rainy\", \"Mild\", \"Normal\", False, \"P\"],\n",
    "        [\"Sunny\", \"Mild\", \"Normal\", True, \"P\"],\n",
    "        [\"Overcast\", \"Mild\", \"High\", True, \"P\"],\n",
    "        [\"Overcast\", \"Hot\", \"Normal\", False, \"P\"],\n",
    "        [\"Rainy\", \"Mild\", \"High\", True, \"N\"],\n",
    "    ],\n",
    "    columns=[\"Outlook\", \"Temperature\", \"Humidity\", \"Wind\", \"Class\"]\n",
    ")\n",
    "df.index = [1+x for x in df.index]\n",
    "df.index.names = [\"Example\"]\n",
    "\n",
    "features = [\"Outlook\", \"Temperature\", \"Humidity\", \"Wind\"]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}